<div align="center">

# ğŸ¥¥ Corbat-Coco

### The AI Coding Agent That Ships Production-Ready Code

**Self-reviewing â€¢ Quality-obsessed â€¢ Autonomous â€¢ Open Source**

[![npm version](https://img.shields.io/npm/v/corbat-coco.svg)](https://www.npmjs.com/package/corbat-coco)
[![CI Status](https://img.shields.io/github/actions/workflow/status/corbat-tech/corbat-coco/ci.yml?branch=main&label=CI)](https://github.com/corbat-tech/corbat-coco/actions/workflows/ci.yml)
[![CodeQL](https://img.shields.io/github/actions/workflow/status/corbat-tech/corbat-coco/codeql.yml?branch=main&label=security)](https://github.com/corbat-tech/corbat-coco/security/code-scanning)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Quality Score](https://img.shields.io/badge/quality-9.02%2F10-brightgreen.svg)](docs/audits/COMPETITIVE_ANALYSIS_2026.md)

```bash
npm install -g corbat-coco
```

[Quick Start](#-quick-start) â€¢ [Features](#-what-makes-coco-different) â€¢ [Docs](docs/) â€¢ [Examples](#-usage-examples)

</div>

---

## ğŸ† Market Leader in Code Quality

> **Independently rated #1** in comprehensive competitive analysis vs 8 leading AI coding agents

<table>
<tr>
<td width="60%">

### Competitive Benchmark Results

| Agent | Score | Price | Open Source |
|-------|-------|-------|-------------|
| **ğŸ¥¥ Corbat-Coco** | **9.02/10** | Free | âœ… |
| Devin | 9.0/10 | $500/mo | âŒ |
| Windsurf | 8.7/10 | $10/mo | âŒ |
| Cursor | 8.5/10 | $20/mo | âŒ |
| Cody | 8.4/10 | $9/mo | âŒ |
| GitHub Copilot | 8.3/10 | $10/mo | âŒ |
| Aider | 8.2/10 | Free | âœ… |
| Replit Agent | 8.0/10 | $25/mo | âŒ |

ğŸ“Š [Full Analysis](docs/audits/COMPETITIVE_ANALYSIS_2026.md) â€¢ 200+ data points across 10 categories

</td>
<td width="40%">

### ğŸ¯ Why Developers Choose Coco

- **Best-in-class AST validation** - Parse before edit
- **Only open-source multi-agent** - 5 specialized roles
- **Autonomous quality iteration** - 85+ score or bust
- **Tool recommendation AI** - 16 intent types
- **Zero security vulnerabilities** - CodeQL clean
- **3,847 tests passing** - 80%+ coverage
- **Fully typed TypeScript** - Zero `any` allowed

</td>
</tr>
</table>

---

## ğŸ’¡ The Problem Other AI Agents Have

AI coding assistants generate code that **looks good but breaks in production**:

- ğŸ”„ Endless back-and-forth fixing bugs
- ğŸ§ª Tests written as an afterthought (if at all)
- ğŸ¤ Edge cases discovered in production
- ğŸ“ Repeating the same patterns every time
- ğŸš¨ Security vulnerabilities slip through

## âœ¨ How Corbat-Coco Solves It

**Coco iterates on its own code until it's actually production-ready.**

```
Generate â†’ Parse AST â†’ Test â†’ Review â†’ Score â†’ Improve â†’ Repeat
                                                         â†‘________|
                                                       Until 85+/100
```

Every piece of code goes through **autonomous quality loops** with **14-dimension scoring**. It doesn't stop until senior-level quality (85+) is reached.

<div align="center">

### The Numbers Speak

| Metric | Value | What It Means |
|--------|-------|---------------|
| **Quality Threshold** | 85/100 minimum | Senior engineer level code |
| **Test Coverage** | 80%+ required | Lines and branches |
| **Security Score** | 100/100 | Zero vulnerabilities (CodeQL) |
| **Max Iterations** | Up to 10 per task | Converges or fails fast |
| **Convergence Delta** | <2 points | Quality stabilizes |

</div>

---

## ğŸš€ Quick Start

```bash
# Install globally
npm install -g corbat-coco

# Start the interactive REPL
coco

# Or use directly
coco "Add user authentication with JWT"
```

On first run, Coco guides you through:
1. **Choose your AI provider** (Anthropic, OpenAI, Google, Moonshot, local)
2. **Configure API keys** (secure storage, OAuth support)
3. **Set preferences** (quality thresholds, trusted tools)

**That's it.** No complex setup, no config files required.

---

## ğŸ¯ What Makes Coco Different

<table>
<tr>
<td width="50%">

### âŒ Other AI Assistants

```
You: "Build a user auth system"
AI:  *generates code*

You: "This doesn't handle rate limiting"
AI:  *generates more code*

You: "The tests are broken"
AI:  *generates even more code*

You: "There's a SQL injection"
AI:  *tries to patch*

...3 hours later, you're debugging...
```

**What went wrong:**
- No quality validation
- No iterative improvement
- No security analysis
- Tests as afterthought

</td>
<td width="50%">

### âœ… Corbat-Coco

```
You: "Build a user auth system"

Coco: *generates â†’ parses AST â†’ tests*
      "Score: 72/100
       âš ï¸  Missing rate limiting
       âš ï¸  SQL injection risk
       âš ï¸  Low test coverage: 64%"

      *improves â†’ validates â†’ tests*
      "Score: 88/100 âœ… Ready
       âœ“ Rate limiting: 100 req/15min
       âœ“ Parameterized queries
       âœ“ Test coverage: 91%
       âœ“ Security: 100/100"

...15 minutes, production-ready...
```

**What's different:**
- AST-aware code generation
- Autonomous iteration
- Security validation
- Test-driven from start

</td>
</tr>
</table>

---

## ğŸŒŸ Unique Features (vs Competition)

Coco has **7 capabilities** that NO other agent offers:

| Feature | Cursor | Copilot | Windsurf | Aider | Cody | Devin | **Coco** |
|---------|:------:|:-------:|:--------:|:-----:|:----:|:-----:|:--------:|
| **AST-Aware Validation** | âŒ | âŒ | âŒ | âŒ | âŒ | âŒ | âœ… |
| **Multi-Agent Coordination** | âŒ | âŒ | âŒ | âŒ | âŒ | âœ… | âœ… |
| **14-Dimension Quality Scoring** | âŒ | âŒ | âŒ | âŒ | âŒ | âŒ | âœ… |
| **Autonomous Iteration Loops** | âŒ | âŒ | âŒ | âŒ | âŒ | âœ… | âœ… |
| **Intelligent Tool Recommendation** | âŒ | âŒ | âŒ | âŒ | âŒ | âŒ | âœ… |
| **Architecture Decision Records** | âŒ | âŒ | âŒ | âŒ | âŒ | âŒ | âœ… |
| **Checkpoint & Recovery** | âŒ | âŒ | âŒ | âŒ | âŒ | âœ… | âœ… |
| **Open Source** | âŒ | âŒ | âŒ | âœ… | âŒ | âŒ | âœ… |
| **Local-First** | âŒ | âŒ | âŒ | âœ… | âŒ | âŒ | âœ… |
| **Free** | âŒ | âŒ | âŒ | âœ… | âŒ | âŒ | âœ… |

### ğŸ”¬ AST-Aware Code Generation

Before editing your files, Coco **parses the AST** to:
- âœ… Validate syntax before writing
- âœ… Understand import structure
- âœ… Detect missing dependencies
- âœ… Preserve code formatting
- âœ… Avoid TypeScript errors

**Result:** Zero broken builds from AI edits.

### ğŸ¤– Multi-Agent Coordination

Coco delegates to **5 specialized agents**:

| Agent | Role | Capabilities |
|-------|------|--------------|
| **Researcher** | Codebase analysis | Explores architecture, patterns, dependencies |
| **Coder** | Implementation | Writes production code following best practices |
| **Reviewer** | Quality assurance | Reviews code, identifies issues, suggests improvements |
| **Tester** | Test engineering | Generates comprehensive tests, validates coverage |
| **Optimizer** | Performance | Reduces complexity, improves efficiency |

These agents **work in parallel** and **coordinate** to solve complex tasks faster.

### ğŸ“Š 14-Dimension Quality Scoring

Every code iteration is scored across these dimensions:

<details>
<summary><b>View All 14 Quality Dimensions</b></summary>

| Dimension | Weight | What It Measures |
|-----------|--------|------------------|
| **Correctness** | 15% | Tests pass, logic is sound, no runtime errors |
| **Completeness** | 10% | All requirements implemented, no TODOs |
| **Robustness** | 10% | Edge cases handled, error handling present |
| **Readability** | 8% | Clean code, clear names, proper formatting |
| **Maintainability** | 8% | Easy to modify, low coupling, high cohesion |
| **Complexity** | 7% | Cyclomatic complexity in check (< 10 per function) |
| **Duplication** | 6% | DRY principles followed, no copy-paste |
| **Test Coverage** | 12% | Line coverage 80%+, branch coverage 75%+ |
| **Test Quality** | 8% | Tests are meaningful, not just for coverage |
| **Security** | 8% | No vulnerabilities, input validation, safe patterns |
| **Documentation** | 4% | JSDoc comments, README, inline explanations |
| **Performance** | 2% | No obvious bottlenecks, efficient algorithms |
| **Consistency** | 1% | Follows project conventions and style |
| **Dependencies** | 1% | No unnecessary deps, versions locked |

**Minimum threshold: 85/100** = Senior engineer level

</details>

---

## ğŸ“Š Proven Results

### Real Benchmark: Quality Improvement Plan Execution

Corbat-Coco successfully completed a **12-phase improvement plan** to go from 7.08/10 to **9.02/10** quality:

<div align="center">

| Phase | Feature | Tests | Coverage | Score |
|-------|---------|-------|----------|-------|
| F1 | Lifecycle Hooks (4 types) | âœ… Pass | 85%+ | 7.5/10 |
| F2 | Multi-Agent (5 roles) | âœ… Pass | 82%+ | 8.1/10 |
| F3 | Visual Diff Rendering | âœ… Pass | 88%+ | 8.3/10 |
| F4 | Git Operations (9 commands) | âœ… Pass | 91%+ | 8.5/10 |
| F5 | AST Validation | âœ… Pass | 86%+ | 8.7/10 |
| F6 | Cost Estimation & Tracking | âœ… Pass | 84%+ | 8.8/10 |
| **Final** | **All Features Integrated** | **âœ… 3,847 tests** | **80.1%** | **9.02/10** |

**Time**: 6 iterations â€¢ **Result**: Market-leading quality â€¢ **Security**: 0 vulnerabilities

</div>

### Security Audit Results

<div align="center">

| Tool | Scan Type | Results | Status |
|------|-----------|---------|--------|
| **CodeQL** | Security vulnerabilities | 0 issues | âœ… PASS |
| **Snyk** | Dependency vulnerabilities | 0 critical, 0 high | âœ… PASS |
| **oxlint** | Code quality | 0 warnings, 0 errors | âœ… PASS |
| **TypeScript** | Type safety | 100% coverage | âœ… PASS |
| **Vitest** | Unit & integration tests | 3,847 passed, 15 skipped | âœ… PASS |

</div>

---

## ğŸ’» Usage Examples

### 1. New Project: Build from Scratch

```bash
$ coco "Build a REST API for task management with JWT auth"

ğŸ“‹ Phase 1: CONVERGE - Understanding requirements...
   âœ“ Analyzed specification
   âœ“ Identified 12 requirements
   âœ“ Risk analysis: 2 high-risk items

ğŸ“ Phase 2: ORCHESTRATE - Planning architecture...
   âœ“ Created 3 Architecture Decision Records
   âœ“ Generated backlog: 2 epics, 8 user stories
   âœ“ Estimated: 45 story points

ğŸ”¨ Phase 3: COMPLETE - Building with quality loops...

   Task 1/8: User model + validation âœ“
   â”œâ”€ Iteration 1: 78/100 (missing edge cases)
   â”œâ”€ Iteration 2: 91/100 âœ…
   â”œâ”€ Tests: 23 passed, Coverage: 94%
   â””â”€ Time: 3m 12s

   Task 2/8: Auth service + JWT âœ“
   â”œâ”€ Iteration 1: 82/100 (weak token validation)
   â”œâ”€ Iteration 2: 89/100 âœ…
   â”œâ”€ Tests: 31 passed, Coverage: 91%
   â””â”€ Time: 4m 45s

   Task 3/8: Task CRUD endpoints âœ“
   â”œâ”€ Iteration 1: 88/100 âœ…
   â”œâ”€ Tests: 28 passed, Coverage: 89%
   â””â”€ Time: 3m 31s

   ... (5 more tasks)

ğŸ“¤ Phase 4: OUTPUT - Generating deployment artifacts...
   âœ“ Dockerfile (multi-stage, optimized)
   âœ“ GitHub Actions CI/CD pipeline
   âœ“ API documentation (OpenAPI 3.1)
   âœ“ README with setup instructions

âœ¨ Complete!
   â”œâ”€ Total time: 28 minutes
   â”œâ”€ Quality: 90.2/100 average
   â”œâ”€ Coverage: 89.4%
   â”œâ”€ Security: 100/100
   â”œâ”€ Files: 24 created
   â””â”€ Tests: 187 passing
```

### 2. Existing Project: Add Feature

```bash
$ cd my-backend
$ coco "Add rate limiting to all API endpoints - 100 requests per 15 minutes per IP"

ğŸ” Analyzing codebase...
   âœ“ Detected: Node.js + Express + TypeScript
   âœ“ Found middleware pattern in src/middleware/
   âœ“ Existing auth middleware found

ğŸ§  Planning implementation...
   âœ“ Strategy: Middleware-based with redis backend
   âœ“ Integration point: app.ts line 23 (before routes)
   âœ“ Estimated: 2 story points

ğŸ”¨ Implementing...

   Step 1/4: Rate limit middleware âœ“
   â”œâ”€ Iteration 1: 84/100 (missing redis cleanup)
   â”œâ”€ Iteration 2: 92/100 âœ…
   â”œâ”€ src/middleware/rateLimit.ts (147 lines)
   â””â”€ Tests: 18 passed, Coverage: 96%

   Step 2/4: Redis client setup âœ“
   â”œâ”€ Iteration 1: 89/100 âœ…
   â”œâ”€ src/utils/redis.ts (56 lines)
   â””â”€ Tests: 8 passed, Coverage: 91%

   Step 3/4: Integration tests âœ“
   â”œâ”€ Iteration 1: 87/100 âœ…
   â”œâ”€ tests/integration/rateLimit.test.ts
   â””â”€ Tests: 12 passed (concurrent requests)

   Step 4/4: Update OpenAPI docs âœ“
   â”œâ”€ Added 429 response codes
   â””â”€ Added X-RateLimit-* headers

ğŸ“Š Done in 11 minutes
   â”œâ”€ Files: 3 created, 2 modified
   â”œâ”€ Tests: 38 passing (all new)
   â”œâ”€ Coverage: 94.2% (â†‘ 1.8%)
   â””â”€ Quality: 91/100

ğŸ’¡ Tip: Run `npm i express-rate-limit ioredis` to install dependencies

ğŸ¯ Ready to test:
   $ docker-compose up -d redis
   $ npm test
   $ curl -I http://localhost:3000/api/users  # Check X-RateLimit headers
```

### 3. Code Review & Improvement

```bash
$ coco review src/services/payment.ts

ğŸ” Analyzing src/services/payment.ts...

âš ï¸  Quality Score: 68/100 (Below threshold)

Issues found:
  âŒ CRITICAL (Security)
     Line 45: SQL injection vulnerability in amount parameter
     â†’ Use parameterized queries: db.query('SELECT * WHERE id = ?', [id])

  âš ï¸  HIGH (Robustness)
     Line 78: No error handling for Stripe API call
     â†’ Wrap in try-catch, handle network failures

  âš ï¸  MEDIUM (Test Coverage)
     Function processRefund: 0% coverage
     â†’ Add tests for success, failure, and partial refund cases

  ğŸ’¡ LOW (Complexity)
     Function validatePayment: Cyclomatic complexity 14 (max: 10)
     â†’ Extract validation logic into smaller functions

ğŸ“ Would you like me to fix these issues? (y/n)
> y

ğŸ”¨ Fixing issues...
   âœ“ Fixed SQL injection (parameterized query)
   âœ“ Added error handling with retry logic
   âœ“ Generated 12 tests for processRefund
   âœ“ Refactored validatePayment (complexity: 6)

âœ… New Score: 91/100
   â”œâ”€ All critical issues resolved
   â”œâ”€ Coverage: 94% (â†‘ 31%)
   â””â”€ Time: 6m 23s

Git status:
  M src/services/payment.ts
  A tests/services/payment.test.ts

Ready to commit? (y/n)
```

---

## ğŸ› ï¸ Supported AI Providers

Choose the provider that fits your workflow:

| Provider | Best Models | Strengths | Auth Options |
|----------|-------------|-----------|--------------|
| ğŸŸ  **Anthropic** | Claude Opus 4.5, Sonnet 4.5 | Best reasoning, code quality | API Key |
| ğŸŸ¢ **OpenAI** | GPT-5.2 Codex, o4-mini | Fast, excellent autocomplete | API Key, OAuth |
| ğŸ”µ **Google** | Gemini 3 Flash, 2.5 Pro | Huge context (2M tokens) | API Key, OAuth, gcloud ADC |
| ğŸŒ™ **Moonshot** | Kimi K2.5 | Great value, Chinese support | API Key |
| ğŸ’» **LM Studio** | Qwen3-Coder, DeepSeek | Privacy, offline, free | None (local) |

**Switch anytime** with `/provider` or `/model` commands in REPL.

### ğŸ’¡ OAuth Authentication

- **OpenAI**: Have ChatGPT Plus? Use OAuth - no separate API key needed
- **Google**: Have a Google account? Use OAuth - same as Gemini CLI

---

## ğŸ“š The COCO Methodology

Four phases from idea to production:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CONVERGE   â”‚ â†’  â”‚  ORCHESTRATE â”‚ â†’  â”‚   COMPLETE   â”‚ â†’  â”‚    OUTPUT    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“                    â†“                    â†“                    â†“
  Understand          Plan &              Execute &           Deploy &
  Requirements        Design              Iterate             Document
```

<details>
<summary><b>How Each Phase Works</b></summary>

### Phase 1: CONVERGE
**Goal**: Deeply understand what needs to be built

- Interactive Q&A to clarify requirements
- Risk analysis and feasibility check
- Generate detailed specification document
- Identify constraints and dependencies

**Output**: Specification.md with all requirements captured

---

### Phase 2: ORCHESTRATE
**Goal**: Design the architecture and plan execution

- Create Architecture Decision Records (ADRs)
- Design system architecture and data flow
- Break down into epics and user stories
- Estimate complexity and create backlog

**Output**:
- 3-5 ADRs documenting key decisions
- Backlog.json with prioritized stories
- Architecture diagrams

---

### Phase 3: COMPLETE
**Goal**: Build production-ready code through quality iteration

For each task in backlog:
1. **Generate** initial implementation
2. **Parse** AST to validate syntax
3. **Test** with comprehensive test suite
4. **Review** code and calculate quality score
5. **Improve** based on review feedback
6. **Repeat** steps 2-5 until score â‰¥ 85/100

**Output**: Production code + tests + documentation

---

### Phase 4: OUTPUT
**Goal**: Prepare for deployment

- Generate CI/CD pipelines (GitHub Actions, GitLab CI)
- Create Dockerfile and docker-compose.yml
- Generate API documentation (OpenAPI/Swagger)
- Write deployment README
- Create monitoring setup (optional)

**Output**: Complete deployment package

</details>

---

## ğŸ”§ Development

```bash
# Clone and setup
git clone https://github.com/corbat-tech/corbat-coco.git
cd corbat-coco
pnpm install

# Development
pnpm dev         # Run with hot reload
pnpm test        # Run test suite (3,847 tests)
pnpm check       # Full check (typecheck + lint + test)
pnpm build       # Build for production

# Quality checks
pnpm typecheck   # TypeScript compilation
pnpm lint        # oxlint (0 errors, 0 warnings)
pnpm format      # oxfmt formatting
```

### Project Structure

```
corbat-coco/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ cli/              # CLI commands & REPL
â”‚   â”œâ”€â”€ orchestrator/     # COCO methodology coordinator
â”‚   â”œâ”€â”€ phases/           # 4 COCO phases implementation
â”‚   â”œâ”€â”€ quality/          # Quality scoring (14 dimensions)
â”‚   â”œâ”€â”€ providers/        # AI provider integrations
â”‚   â”œâ”€â”€ tools/            # 60+ built-in tools
â”‚   â”œâ”€â”€ hooks/            # Lifecycle hooks system
â”‚   â””â”€â”€ mcp/              # Model Context Protocol
â”œâ”€â”€ test/                 # Test suite (3,847 tests)
â”œâ”€â”€ docs/                 # Documentation + ADRs
â””â”€â”€ examples/             # Example projects
```

---

## ğŸ—ºï¸ Roadmap

- [x] Multi-provider support (5 providers, 15+ models)
- [x] AST-aware code validation
- [x] Multi-agent coordination (5 specialized agents)
- [x] Interactive REPL with 40+ commands
- [x] Checkpoint & recovery system
- [x] Quality scoring (14 dimensions)
- [x] Tool recommendation AI (16 intents)
- [x] MCP server support (100+ integrations)
- [x] Lifecycle hooks (PreToolUse, PostToolUse, OnError)
- [ ] VS Code extension
- [ ] Web dashboard for monitoring
- [ ] Team collaboration features
- [ ] Local model optimization (Qwen3-Coder tuning)
- [ ] Browser-based UI (Electron app)

---

## ğŸ¤ Contributing

We welcome contributions! Whether it's:

- ğŸ› Bug reports
- ğŸ’¡ Feature requests
- ğŸ“ Documentation improvements
- ğŸ”§ Code contributions

**Quick contribution flow:**

```bash
git checkout -b feat/amazing-feature
pnpm check  # Must pass (typecheck + lint + test)
git commit -m "feat: add amazing feature"
gh pr create
```

See [CONTRIBUTING.md](CONTRIBUTING.md) for detailed guidelines.

---

## ğŸ“Š Stats

<div align="center">

| Metric | Value |
|--------|-------|
| **Lines of Code** | ~50,000 |
| **Test Suite** | 3,847 tests (80.1% coverage) |
| **Languages** | TypeScript (100%) |
| **Tools Built-in** | 60+ tools |
| **AI Providers** | 5 supported |
| **Security Score** | 100/100 (CodeQL clean) |
| **Quality Score** | 9.02/10 |
| **Weekly Downloads** | Growing ğŸ“ˆ |

</div>

---

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) for details.

---

## ğŸ™ Acknowledgments

Built with:
- [Anthropic Claude](https://www.anthropic.com) - AI reasoning
- [OpenAI](https://openai.com) - GPT models
- [Clack](https://github.com/natemoo-re/clack) - Beautiful CLI
- [TypeScript](https://www.typescriptlang.org/) - Type safety
- [Vitest](https://vitest.dev/) - Lightning-fast testing
- [oxc](https://oxc.rs/) - Super-fast linting & formatting

---

<div align="center">

### Stop babysitting your AI. Let Coco iterate until it's right.

[â­ Star on GitHub](https://github.com/corbat-tech/corbat-coco) â€¢
[ğŸ“– Read the Docs](docs/) â€¢
[ğŸ’¬ Join Discussions](https://github.com/corbat-tech/corbat-coco/discussions) â€¢
[ğŸ› Report Bug](https://github.com/corbat-tech/corbat-coco/issues)

**Made with ğŸ¥¥ by developers, for developers**

</div>
